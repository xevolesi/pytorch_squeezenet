path:
  dataset:
    root_dir: /home/xevolesi/Datasets/ImageNet
    meta_file_path: /home/xevolesi/Datasets/ImageNet/meta.json

training:
  batch_size: 512
  image_size: 227
  dataloader_num_workers: 6
  device: cuda:0
  epochs: 100

model:
  __name__: source.models.SqueezeNet
  in_channels: 3
  num_classes: 1000

augmentations:
  train:
    transform:
      __class_fullname__: Compose
      transforms:
        - __class_fullname__: albumentations.augmentations.crops.transforms.RandomResizedCrop
          height: 227
          width: 227
          always_apply: true

        # To PyTorch tensors.
        - __class_fullname__: albumentations.augmentations.transforms.Normalize
          always_apply: true

          # We won't divide by 255.
          max_pixel_value: 1.0
          mean:
            - 123
            - 117
            - 104
          
          # Don't do Z-standardization.
          std:
            - 1
            - 1
            - 1
        - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
          always_apply: true
  val:
    transform:
      __class_fullname__: Compose
      transforms:
        - __class_fullname__: albumentations.augmentations.geometric.resize.Resize
          height: 288
          width: 288
          always_apply: true
        - __class_fullname__: albumentations.augmentations.crops.transforms.CenterCrop
          height: 227
          width: 227
          always_apply: true

        # To PyTorch tensors.
        - __class_fullname__: albumentations.augmentations.transforms.Normalize
          always_apply: true
          # We won't divide by 255.
          max_pixel_value: 1.0
          mean:
            - 123
            - 117
            - 104
          # Don't do Z-standardization.
          std:
            - 1
            - 1
            - 1
        - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
          always_apply: true